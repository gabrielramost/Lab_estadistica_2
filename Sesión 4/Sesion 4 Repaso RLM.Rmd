---
title: "Sesión 4. Repaso RLM"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

## Abrir base de datos

```{r echo=FALSE}
library(rio)
data=import("https://github.com/gabrielramost/Lab_estadistica_2/blob/main/Sesi%C3%B3n%204/trabajadores.sav?raw=true")
```

Vamos a determinar y analizar el mejor modelo para determinar los principales predictores que permitan explicar el salario actual de los trabajadores de la empresa de esta base de datos. 

```{r eval=FALSE}
names(data)
```

Las variables son
- sexo: Describe el sexo del trabajador, siendo "0" mujer y "1" hombre.
- fechanac: Fecha de nacimiento del trabajador
- educ: Años de estudio o formación educativa del entrevistado.
- catlab: Categoría laboral a la que pertenece el entrevistado siendo 1. Administrativo / 2. Seguridad / 3. Directivo.
- salario_actual: En unidades monetarias.
- salario_inicial: Salario con el que el entrevistado ingresó a la empresa, en unidades monetarias. 
- antiguedad: Tiempo en meses de estancia en la empresa.
- experiencia: Experiencia previa del trabajador en meses, antes de ingresar a la empresa.
- minoría: Si pertenece o no a un grupo minoritario siendo "0" que no pertenece y "1" que si pertenece.
- directivo: Si pertenece o no al grupo directivo de la empresa siendo "0" que no pertenece y "1" que si pertenece.

## Configuración de variables

```{r}
data$sexo<-as.factor(data$sexo)
levels(data$sexo)<-c("Mujer","Hombre")
levels(data$sexo)

data$catlab<-as.ordered(data$catlab)
levels(data$catlab)<-c("Administrativo","Seguridad","Directivo")
levels(data$catlab)

data$minoría<-as.factor(data$minoría)
levels(data$minoría)<-c("No","Si")
levels(data$minoría)

data$directivo<-as.factor(data$directivo)
levels(data$directivo)<-c("No","Si")
levels(data$directivo)

```

# A. Regresión lineal o gaussiana

## Con estas variables vamos a buscar construir un modelo que nos permita explicar el salario actual de los trabajadores de esta empresa

**Modelo 1**

```{r}
modelo1<-lm(salario_actual~educ+ antiguedad + experiencia, data)
summary(modelo1)
```

**Modelo 2**

```{r}
modelo2<-lm(salario_actual~salario_inicial + antiguedad + experiencia, data)
summary(modelo2)
```

**Comparamos modelos** 

```{r}
library(stargazer)
stargazer(modelo1,modelo2, type ="text")
```

¿Qué modelo es el mejor? Veamos el R2 y el aporte de las variables. También podemos utilizar anova para comparación de modelos.
La comparación de modelos usando la tabla de análisis de varianza (anova) propone como hipótesis nula que los modelos no difieren (no se ha reducido el error al pasar de un modelo a otro).

Nos quedamos con el modelo 2

## Diagnósticos de la regresión

### 1. Linealidad

Se asume una relación lineal de las Ys y las Xs. Para evaluar la linealidad podemos utilizar un gráfico residual que evalúa los residuos y los valores Esperados de Y. La diferencia entre el valor observado de la variable dependiente (y) y el valor predicho (ŷ) se denomina residuo (e). Cada punto de datos tiene un residuo y se espera que el promedio de los residuos sea cercano a 0.

```{r}
plot(modelo2,1) #Se espera que la línea roja tienda a la horizontal
```

O también:

```{r}
mean(modelo2$residuals) # Se espera que el promedio de los residuos sea cercano a 0
```

### 2. Homocedasticidad

Todas las distribuciones poblacionales tienen la misma varianza. Por tanto, se asume que el error del modelo de regresión no afecta la varianza o dispersión de la estimación, en la medida que también se mantiene constante. Para evaluarlo podemos utilizar un gráfico de Scale-location plot. También podemos utilizar el test de Breusch-Pagan. La homocedasticidad es lo contrario a la heterocedasticidad.

```{r}
plot(modelo2,3) # Se espera que la línea roja debe tender a horizontal.
```

```{r}
library(lmtest)
bptest(modelo2) #H0 = Modelo homocedástico, ojo aquí buscamos que sea mayor a 0.05 para cumplir con el requisito
```

### 3. Normalidad de residuos

Los residuos (la distancia entre el valor esperado y el observado de la variable) deben distribuirse de manera normal. Para evaluarlo podemos utilizar un gráfico de Residuos vs distribución normal (Normal Q-Q) , o podemos aplicar el test de Shapiro Wilk.

```{r}
plot(modelo2,2) # En este caso la expectativa es que los puntos se acerquen lo más posible a la línea oblicua del gráfico que representa una distribución normal
```

```{r}
shapiro.test(modelo2$residuals) #H0= Hay normalidad
```

### 4. No multicolinealidad

La multicolinealidad es una situación en la que se presenta una fuerte correlación entre variables explicativas del modelo. Cuando el valor de la prueba VIF es mayor a 5 significa que esa variable tiene una fuerte correlación con otras variables incluidas en el modelo. Para evaluarlo podemos utilizar el Factor de Inflación de la Varianza

```{r}
library(DescTools)
VIF(modelo2) #>5 es problemático
```

### 5. Valores influyentes

Los valores influyentes con casos en nuestra data que no siguen el patrón general del resto de casos. No todos los valores atípicos influyen en el análisis de regresión. Aunque nuestros datos tengan valores extremos, es posible que no sean influyentes para determinar una línea de regresión. Eso significa que los resultados no serían muy diferentes si los incluyéramos o los excluyéramos del análisis.

```{r}
plot(modelo2,5) #miramos valores fuera de las lineas punteadas
```

```{r}
checModelo2=as.data.frame(influence.measures(modelo2)$is.inf)
checModelo2[checModelo2$cook.d & checModelo2$hat,] #visualizamos valores 
```

